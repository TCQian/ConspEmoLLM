{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "def clean_unicode(text):\n",
    "    return unicodedata.normalize(\"NFKC\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "Task: Determine if the text is a conspiracy theory. Classify it into one of the following two classes: 0. non-conspiracy. 1. conspiracy.\n",
      "Text: Coronavirus is indiscriminate. We have seen young and old affected, rich and poor. In the UK alone, we have seen the Prime Minister himself succumb to it and even Prince Charles. But this pandemic has repercussions beyond our nation states. In a short time, it has paralysed the ‘developed’ world and threatened its very existence.\n",
      "\n",
      "The unipolar world as we know it is being questioned like never before. Nations demonised in the West – Russia, China and Cuba – have been the very countries sending aid to the West.\n",
      "\n",
      "Never has one witnessed a more ironic act than the US accepting aid from Russia, its arch geopolitical enemy and ‘the primary threat to American interests’ – according to a survey published last year by a US think-tank. The Antonov An-124-100 cargo plane delivered vital medical equipment and masks from Moscow to the US on Wednesday at a time when the country is struggling to cope with coronavirus. There are already 333,173 cases and 9536 deaths in a nation whose leader Donald Trump initially refused to recognise the severity of the situation, claiming it was ‘like the flu’ before excusing his administration’s inaction by saying ‘Nobody knew there would be a pandemic or epidemic of this proportion’. The outlook is pretty grim for the US.\n",
      "\n",
      "Russia has, on the other hand, as have many Asian countries so far, dealt with the virus efficiently and effectively – so much so that Russian watchers got suspicious and began penning articles on the subject that the country was covering up the real figures. There are still articles in western mainstream media claiming there is a cover-up, with people at a loss as to why the country of 146 million has fewer cases than Norway. In fact there are various possible reasons why Russia has reacted to the virus more slowly than other nations. Firstly, it closed its border with China very early in the crisis – back on 30th January – even before any cases were reported. Secondly, it set up strict quarantine rules to ensure that anyone travelling from abroad was isolated for two weeks. In addition, the government has undertaken a thorough approach to testing. Although only just over 4000 infected to date, according to official statistics, over 575,000 tests have been carried out in Russia (there is an official website devoted to the outbreak where people can get up to date information and advice). In this regard the Russian government could not be more transparent. This number of tests could be compared to the UK at present, where only 150,000 tests have been carried out, despite the number of cases reaching over 47,000. Thirdly, it has been speculated that Russians may have greater immunity to the virus as a result of the Soviet vaccination programme for tuberculosis; it has been noted that in eastern parts of Germany there have been fewer cases, and suggested this is down to greater immunity which dates back to when German Democratic Republic existed.\n",
      "\n",
      "Whatever the reason is for the delay of the pandemic in Russia, the country’s strict measures have clearly played a role. China, although initially unable to determine what it was dealing with, swiftly moved to implement a nationwide lockdown and massive testing programme. This has enabled the country to overcome the worst of the pandemic and drastically reduce the number of cases it sees on a daily basis – on Friday it was as low as 31.\n",
      "\n",
      "The country has also taken part, as has Russia, in sending aid to other parts of the globe such as Italy, which is struggling to manage the disease, with over 15,000 deaths to date. The equipment came with a message ‘The friendship road knows no borders’, which very much expresses the spirit of this cooperation. And despite all sorts of theories being espoused by mainstream media as to the motivation behind China and Russia’s actions, politics and propaganda ought to be set aside at a time like this, and such gestures taken at face value. This is not a time for political points to be scored; people’s lives are at stake.\n",
      "\n",
      "But even after this is over – and it will be, eventually – surely governments will have to rethink their strategies. For years now the security services in the US and UK have been obsessed with the ‘Russian threat’. But by focusing on this almost mythical monster of ‘Putin’s Russia’, painted as poised to invade Europe at any second and begin World War Three, real threats have surfaced and materialized to our detriment. Terrorism being one, pandemics another. It emerged recently that the British security services were aware that Taiwan was testing for coronavirus back in December, but failed to act – why? Why have western governments been so ill-prepared for a pandemic that epidemiologists have been warning about for years?\n",
      "\n",
      "Surely, after this international effort to save our populations, governments will have to reassess their priorities. Surely, after this struggle, and the spirit of cooperation which has been generated, the West will have to recognize Russia, China and others as equal partners, and not nations to be sanctioned when they take geopolitical decisions the West doesn’t agree with. Surely, after this is over, the multipolar world will be born.\n",
      "\n",
      "Note to readers: please click the share buttons above or below. Forward this article to your email lists. Crosspost on your blog site, internet forums. etc.\n",
      "\n",
      "This article was originally published on InfoBrics.\n",
      "Class:\n",
      "\n",
      "\n",
      "Assistant:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "infer_data = pd.read_json('./data/loco_test_conspemollm.json', lines=True)\n",
    "instruction_list = infer_data.apply(\n",
    "    lambda row: pd.Series(\n",
    "        {\n",
    "            \"instruction\": clean_unicode(\n",
    "                f\"Human: \\n\" + row[\"instruction\"] + \"\\n\\nAssistant:\\n\"\n",
    "            )\n",
    "        }\n",
    "    ),\n",
    "    axis=1,\n",
    ")[\"instruction\"].to_list()\n",
    "print(instruction_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "# get first row\n",
    "if 'output' in infer_data.iloc[0]:\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n",
    "\n",
    "max_new_tokens = 1024\n",
    "generation_config = dict(\n",
    "    temperature=0.9,\n",
    "    top_k=30,\n",
    "    top_p=0.6,\n",
    "    do_sample=True,\n",
    "    num_beams=1,\n",
    "    repetition_penalty=1.2,\n",
    "    max_new_tokens=max_new_tokens,\n",
    ")\n",
    "\n",
    "load_type = torch.float16  # Sometimes may need torch.float32\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('./model/ConspEmoLLM-7b')\n",
    "tokenizer.pad_token_id = 0\n",
    "tokenizer.bos_token_id = 1\n",
    "tokenizer.eos_token_id = 2\n",
    "tokenizer.padding_side = \"left\"\n",
    "model_config = AutoConfig.from_pretrained('./model/Emollama-chat-7b')\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    './model/Emollama-chat-7b',\n",
    "    torch_dtype=load_type,\n",
    "    config=model_config,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "if device.type == \"cpu\":\n",
    "    model.float()\n",
    "\n",
    "model.eval()\n",
    "print(\"Load model successfully\")\n",
    "print(model.config.max_position_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 12 files: 100%|██████████| 12/12 [02:56<00:00, 14.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model downloaded to: /Users/honhaochen/Documents/ConspEmoLLM/model/ConspEmoLLM-7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "model_path = snapshot_download(repo_id=\"lzw1008/ConspEmoLLM-7b\", local_dir=\"./model/ConspEmoLLM-7b\")\n",
    "\n",
    "print(\"Model downloaded to:\", model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncated text: testing, hello world\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('./model/ConspEmoLLM-7b')\n",
    "tokenizer.pad_token_id = 0\n",
    "tokenizer.bos_token_id = 1\n",
    "tokenizer.eos_token_id = 2\n",
    "tokenizer.padding_side = \"left\"\n",
    "\n",
    "input_txt = \"testing, hello world\"\n",
    "truncated_text = tokenizer.decode(\n",
    "    tokenizer(input_txt, truncation=True, max_length=1800, add_special_tokens=False)[\"input_ids\"],\n",
    "    skip_special_tokens=True,\n",
    "    spaces_between_special_tokens=False,\n",
    ")\n",
    "print(\"Truncated text:\", truncated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "both ConspEmoLLM and Emollama-chat-7b has max_position_embeddings of 2048\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
